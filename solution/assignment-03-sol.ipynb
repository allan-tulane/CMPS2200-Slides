{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# assignment-03\n",
    "\n",
    "\n",
    "## Part 1: Searching Unsorted Lists\n",
    "\n",
    "As we know, the binary search algorithm takes as input a sorted list\n",
    "of length $n$ and a specified key and is able to find it (or conclude\n",
    "that it is not in the list) in $O(\\log n)$ time. Let's consider a\n",
    "slightly different problem in which we are given an unsorted list $L$\n",
    "with a key $x$, and we want determine whether $x$ is in $L$. For each\n",
    "part below, design an algorithm using the prescribed sequence\n",
    "operation. Note that you can preprocess the list as needed.\n",
    "\n",
    "**1a)** Use `iterate` to implement the `isearch` stub, and check that your\n",
    "code passes the test cases given by `test_isearch` (feel free to add\n",
    "additional cases). \n",
    "\n",
    ".  \n",
    ".  \n",
    "\n",
    "**1b)** What is the work and span of this algorithm?\n",
    "\n",
    "> $O(n)$ work and $O(n)$ span\n",
    "\n",
    ".  \n",
    ".  \n",
    "\n",
    "\n",
    "**1c)** Now, use `reduce` to implement the `rsearch` stub. Test it with `test_rsearch`.\n",
    "\n",
    "\n",
    ".  \n",
    "\n",
    "**1d)** What is the work and span of the resulting algorithm, assuming that `reduce` is implemented as specified in the lecture notes?\n",
    "\n",
    "> $O(n)$ work and $O(\\lg n)$ span\n",
    "\n",
    ".  \n",
    "\n",
    "\n",
    "**1e)** Finally, let's consider another implementation of `reduce` as given\n",
    "by `ureduce` in `main.py`. That is, if you replace `reduce` from part b) with\n",
    "`ureduce` then there should be no difference in output. However, what\n",
    "is the work and span of the resulting algorithm for `rsearch`?\n",
    "\n",
    "> $W(n) = W(n/3) + W(2n/3) + 1$\n",
    "\n",
    "> $W(n) = O(n)$\n",
    "\n",
    "> leaf dominated (1 -> 2 -> 4 -> ...)\n",
    "\n",
    "> we know that the total number of leaves is $n$ -- no part of the input is inspected more than once.\n",
    "\n",
    "> $S(n) = O(\\lg n)$\n",
    "\n",
    "> balanced: (1->1->1->1)\n",
    "\n",
    "> worst levels  * number of levels\n",
    "\n",
    "> base of log doesn't matter for big O\n",
    "\n",
    "> $\\lg_{3/2} n \\in O(\\lg n)$\n",
    "\n",
    ".  \n",
    ".  \n",
    ".  \n",
    "> Why doesn't base of log matter for big O? recall change of base formula:\n",
    "\n",
    "> $\\log_a n = \\frac{\\log_b n}{\\log_b a}$, where $\\log_b a$ is a constant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "### PART 1: SEARCHING UNSORTED LISTS\n",
    "\n",
    "# search an unordered list L for a key x using iterate\n",
    "def isearch(L, key):\n",
    "    ###TODO\n",
    "    def search_f(key, cur_output, next_input):\n",
    "        return next_input == key or cur_output\n",
    "    return iterate(lambda c,n: search_f(key, c, n), False, L)\n",
    "    ###\n",
    "\n",
    "def test_isearch():\n",
    "    assert isearch([1, 3, 5, 4, 2, 9, 7], 2) == (2 in [1, 3, 5, 4, 2, 9, 7])\n",
    "    assert isearch([1, 3, 5, 2, 9, 7], 7) == (7 in [1, 3, 5, 2, 9, 7])\n",
    "    assert isearch([1, 3, 5, 2, 9, 7], 99) == (99 in [1, 3, 5, 2, 9, 7])\n",
    "    assert isearch([], 2) == (2 in [1, 3, 5])\n",
    "\n",
    "\n",
    "def iterate(f, x, a):\n",
    "    # done. do not change me.\n",
    "    if len(a) == 0:\n",
    "        return x\n",
    "    else:\n",
    "        return iterate(f, f(x, a[0]), a[1:])\n",
    "\n",
    "# search an unordered list L for a key x using reduce\n",
    "def rsearch(L, x):\n",
    "    ###TODO\n",
    "    def search_f(x, a, b):\n",
    "        return a==x or b==x or a is True or b is True\n",
    "    return reduce(lambda c,n: search_f(x, c, n), False, L)\n",
    "    ###\n",
    "\n",
    "def test_rsearch():\n",
    "    assert rsearch([1, 3, 5, 4, 2, 9, 7], 2) == (2 in [1, 3, 5, 4, 2, 9, 7])\n",
    "    assert rsearch([1, 3, 5, 2, 9, 7], 7) == (7 in [1, 3, 5, 2, 9, 7])\n",
    "    assert rsearch([1, 3, 5, 2, 9, 7], 99) == (99 in [1, 3, 5, 2, 9, 7])\n",
    "    assert rsearch([], 2) == (2 in [1, 3, 5])\n",
    "\n",
    "def reduce(f, id_, a):\n",
    "    # done. do not change me.\n",
    "    if len(a) == 0:\n",
    "        return id_\n",
    "    elif len(a) == 1:\n",
    "        return a[0]\n",
    "    else:\n",
    "        # can call these in parallel\n",
    "        res = f(reduce(f, id_, a[:len(a)//2]),\n",
    "                 reduce(f, id_, a[len(a)//2:]))\n",
    "        return res\n",
    "\n",
    "    \n",
    "def ureduce(f, id_, a):\n",
    "    if len(a) == 0:\n",
    "        return id_\n",
    "    elif len(a) == 1:\n",
    "        return a[0]\n",
    "    elif len(a) == 2:\n",
    "        return f(a[0], a[1])\n",
    "    else:\n",
    "        # can call these in parallel\n",
    "        return f(ureduce(f, id_, a[:len(a)//3]),\n",
    "                 ureduce(f, id_, a[len(a)//3:]))\n",
    "    \n",
    "# def ureduce(f, id_, a):\n",
    "#     if len(a) == 0:\n",
    "#         return id_\n",
    "#     elif len(a) == 1:\n",
    "#         return a[0]\n",
    "#     else:\n",
    "#         # can call these in parallel\n",
    "#         return f(reduce(f, id_, a[:len(a)//3]),\n",
    "#                  reduce(f, id_, a[len(a)//3:]))\n",
    "\n",
    "\n",
    "test_isearch()\n",
    "test_rsearch()\n",
    "# rsearch([1, 3, 5, 4, 2, 9, 7,10,2,102,1,201,2], 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Part 2: Document indexing\n",
    "\n",
    "A key component of search engines is a data structure called an **inverted index** which maps each word to the list of documents it appears in.\n",
    "\n",
    "Assume we have three documents with ids 0,1,2:\n",
    "\n",
    "```python\n",
    "[\n",
    "    ('document one is cool is it', 0),\n",
    "    ('document two is also cool', 1),\n",
    "    ('document three is kinda neat', 2)\n",
    "]\n",
    "```\n",
    "\n",
    "then an inverted index would be\n",
    "\n",
    "```python\n",
    "[('also', [1]),\n",
    " ('cool', [0, 1]),\n",
    " ('document', [0, 1, 2]),\n",
    " ('is', [0, 1, 2]),\n",
    " ('it', [0]),\n",
    " ('kinda', [2]),\n",
    " ('neat', [2]),\n",
    " ('one', [0]),\n",
    " ('three', [2]),\n",
    " ('two', [1])]\n",
    "```\n",
    "\n",
    "To implement this in map-reduce, we will implement our own map and reduce functions, similar to `recitation-04`.\n",
    "\n",
    "The map function `doc_index_map` is already complete. E.g.\n",
    "\n",
    "```python\n",
    ">>> doc_index_map('document one is cool is it', 0)\n",
    "    [('document', 0), ('one', 0), ('is', 0), ('cool', 0), ('is', 0), ('it', 1)] \n",
    "```\n",
    "\n",
    "The reduce function is also implemented, but it has a bug:\n",
    "\n",
    "```python\n",
    ">>> doc_index_reduce(['is', [0,0,1,2]])\n",
    "    ('is', [0,0,1,2])\n",
    "```\n",
    "\n",
    "The problem is that document ids are duplicated in the final output (e.g., `0` in the above example).\n",
    "\n",
    "While of course we could just fix `doc_index_map` to not emit duplicates, we will instead modify the `doc_index_reduce` function. We will do so with the help of another function `dedup` which takes in two sorted, deduplicated lists and returns their concatenation without any duplicates:\n",
    "\n",
    "```python\n",
    ">>> dedup([1,2,3], [3,4,5])\n",
    "[1,2,3,4,5]\n",
    "```\n",
    "\n",
    "1a. Implement `dedup` **in constant time** and test it with `test_dedup`. \n",
    "\n",
    "1b. Modify the `doc_index_reduce` function to use both `dedup` and `reduce`. Test it with `test_doc_index_reduce`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "def run_map_reduce(map_f, reduce_f, docs):\n",
    "    # done. do not change me.\n",
    "    \"\"\"    \n",
    "    The main map reduce logic.\n",
    "    \n",
    "    Params:\n",
    "      map_f......the mapping function\n",
    "      reduce_f...the reduce function\n",
    "      docs.......list of input records\n",
    "    \"\"\"\n",
    "    # 1. call map_f on each element of docs and flatten the results\n",
    "    # e.g., [('i', 1), ('am', 1), ('sam', 1), ('i', 1), ('am', 1), ('sam', 1), ('is', 1), ('ham', 1)]\n",
    "    pairs = flatten(list(map(map_f, docs)))\n",
    "    # 2. group all pairs by by their key\n",
    "    # e.g., [('am', [1, 1]), ('ham', [1]), ('i', [1, 1]), ('is', [1]), ('sam', [1, 1])]\n",
    "    groups = collect(pairs)\n",
    "    # 3. reduce each group to the final answer\n",
    "    # e.g., [('am', 2), ('ham', 1), ('i', 2), ('is', 1), ('sam', 2)]\n",
    "    return [reduce_f(g) for g in groups]\n",
    "\n",
    "\n",
    "def doc_index_map(doc_tuple):\n",
    "    \"\"\"\n",
    "    Params:\n",
    "      doc_tuple....a tuple (docstring, docid)\n",
    "    Returns:\n",
    "      a list of tuples of form (word, docid), where token is a whitespace delimited element of this string.\n",
    "\n",
    "    Note that the returned list can contain duplicates.\n",
    "    E.g.\n",
    "    >>> doc_index_map('document one is cool is it', 0)\n",
    "    [('document', 0), ('one', 0), ('is', 0), ('cool', 0), ('is', 0), ('it', 1)]    \n",
    "    \"\"\"\n",
    "    ### done. do not change me.\n",
    "    doc, docid = doc_tuple[0], doc_tuple[1]\n",
    "    return [(token, docid) for token in doc.split()]\n",
    "\n",
    "def dedup(a, b):\n",
    "    \"\"\"\n",
    "    Return a concatenation of two lists without any duplicates.\n",
    "    Assume that input lists a and b already sorted and deduplicated.\n",
    "    This should be done in _constant_ time (ignoring any time to create or concatenate lists).\n",
    "    e.g.\n",
    "    >>> dedup([1,2,3], [3,4,5])\n",
    "    [1,2,3,4,5]\n",
    "    \"\"\"\n",
    "    ###TODO\n",
    "    if a[-1] == b[0]:\n",
    "        return a[:-1] + b\n",
    "    else:\n",
    "        return a+b\n",
    "    ###\n",
    "    \n",
    "def doc_index_reduce(group):\n",
    "    \"\"\"\n",
    "    Fix this function to instead call the reduce and dedup functions\n",
    "    to return the _unique_ list of document ids that this word appears in.\n",
    "    \n",
    "    Params:\n",
    "      group...a tuple of the form (word, list_of_docids), indicating the docids containing this word, with duplicates.\n",
    "    Returns:\n",
    "      tuple of form (word, list_of_docids), where duplicate docids have been removed.\n",
    "      \n",
    "    >>> doc_index_reduce(['is', [0,0,1,2]])\n",
    "    ('is', [0,1,2])\n",
    "    \"\"\"\n",
    "    # fix this line\n",
    "    # return (group[0], group[1])\n",
    "    ###TODO\n",
    "    return (group[0], reduce(dedup, [], [[x] for x in group[1]]))\n",
    "    ###\n",
    "    \n",
    "def test_dedup():\n",
    "    assert dedup([1,2,3], [3,4,5]) == [1,2,3,4,5]\n",
    "    assert dedup([1,2,3], [5,6]) == [1,2,3,5,6]\n",
    "    \n",
    "def test_doc_index_reduce():\n",
    "    assert doc_index_reduce(['is', [0,0,1,2]]) == ('is', [0,1,2])\n",
    "    assert doc_index_reduce(['is', [0,0,0,0,1,1,1,1,1,1,2,2,2,2]]) == ('is', [0,1,2])\n",
    "\n",
    "def test_index():\n",
    "    res = run_map_reduce(doc_index_map, doc_index_reduce,\n",
    "               [('document one is cool is it', 0),\n",
    "                ('document two is also cool', 1),\n",
    "                ('document three is kinda neat', 2)\n",
    "               ])    \n",
    "    assert res == [('also', [1]),\n",
    "                   ('cool', [0, 1]),\n",
    "                   ('document', [0, 1, 2]),\n",
    "                   ('is', [0, 1, 2]),\n",
    "                   ('it', [0]),\n",
    "                   ('kinda', [2]),\n",
    "                   ('neat', [2]),\n",
    "                   ('one', [0]),\n",
    "                   ('three', [2]),\n",
    "                   ('two', [1])]\n",
    "    \n",
    "\n",
    "def collect(pairs):\n",
    "    \"\"\"\n",
    "    Implements the collect function (see text Vol II Ch2)\n",
    "    >>> collect([('i', 1), ('am', 1), ('sam', 1), ('i', 1)])\n",
    "    [('am', [1]), ('i', [1, 1]), ('sam', [1])]    \n",
    "    \"\"\"\n",
    "    ### done\n",
    "    result = defaultdict(list)\n",
    "    for pair in sorted(pairs):\n",
    "        result[pair[0]].append(pair[1])\n",
    "    return list(result.items())\n",
    "\n",
    "\n",
    "def plus(x, y):\n",
    "    # done. do not change me.\n",
    "    return x + y\n",
    "\n",
    "def iterate(f, x, a):\n",
    "    # done. do not change me.\n",
    "    \"\"\"\n",
    "    Params:\n",
    "      f.....function to apply\n",
    "      x.....return when a is empty\n",
    "      a.....input sequence\n",
    "    \"\"\"\n",
    "    if len(a) == 0:\n",
    "        return x\n",
    "    else:\n",
    "        return iterate(f, f(x, a[0]), a[1:])\n",
    "    \n",
    "def flatten(sequences):\n",
    "    # done. do not change me.\n",
    "    return iterate(plus, [], sequences)\n",
    "\n",
    "def reduce(f, id_, a):\n",
    "    # done. do not change me.\n",
    "    if len(a) == 0:\n",
    "        return id_\n",
    "    elif len(a) == 1:\n",
    "        return a[0]\n",
    "    else:\n",
    "        return f(reduce(f, id_, a[:len(a)//2]),\n",
    "                 reduce(f, id_, a[len(a)//2:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_items([('a', 1), ('b', 2)])\n",
      "dict_items([('b', 1), ('a', 2)])\n"
     ]
    }
   ],
   "source": [
    "# as of python 3.7, dictionaries preserve insertion order.\n",
    "d = dict()\n",
    "d['a'] = 1\n",
    "d['b'] = 2\n",
    "print(d.items())\n",
    "\n",
    "e = dict()\n",
    "e['b'] = 1\n",
    "e['a'] = 2\n",
    "print(e.items())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Parenthesis Matching\n",
    "\n",
    "A common task of compilers is to ensure that parentheses are matched. That is, each open parenthesis is followed at some point by a closed parenthesis. Furthermore, a closed parenthesis can only appear if there is a corresponding open parenthesis before it. So, the following are valid:\n",
    "\n",
    "- `( ( a ) b )`\n",
    "- `a () b ( c ( d ) )`\n",
    "\n",
    "but these are invalid:\n",
    "\n",
    "- `( ( a )`\n",
    "- `(a ) ) b (`\n",
    "\n",
    "Below, we'll solve this problem three different ways, using iterate, scan, and divide and conquer.\n",
    "\n",
    "**2a. iterative solution** Implement `parens_match_iterative`, a solution to this problem using the `iterate` function. **Hint**: consider using a single counter variable to keep track of whether there are more open or closed parentheses. How can you update this value while iterating from left to right through the input? What must be true of this value at each step for the parentheses to be matched? To complete this, complete the `parens_update` function and the `parens_match_iterative` function. The `parens_update` function will be called in combination with `iterate` inside `parens_match_iterative`. Test your implementation with `test_parens_match_iterative`.\n",
    "\n",
    ".  \n",
    ". \n",
    "\n",
    "\n",
    "\n",
    "**2b.** What are the recurrences for the Work and Span of this solution? What are their Big Oh solutions?\n",
    "\n",
    "\n",
    "> $W(n) = O(n)$\n",
    "\n",
    "> $S(n) = O(n)$\n",
    "\n",
    ".  \n",
    ". \n",
    "\n",
    "\n",
    "\n",
    "**2c. scan solution** Implement `parens_match_scan` a solution to this problem using `scan`. **Hint**: We have given you the function `paren_map` which maps `(` to `1`, `)` to `-1` and everything else to `0`. How can you pass this function to `scan` to solve the problem? You may also find the `min_f` function useful here. Implement `parens_match_scan` and test with `test_parens_match_scan`\n",
    "\n",
    ".  \n",
    ". \n",
    "\n",
    "\n",
    "\n",
    "**2d.** Assume that any `map`s are done in parallel, and that we use the efficient implementation of `scan` from class. What are the recurrences for the Work and Span of this solution? \n",
    "\n",
    "```python\n",
    "    history, last = scan(plus, 0, list(map(paren_map, mylist)))\n",
    "    return last == 0 and reduce(min_f, 0, history) >= 0\n",
    "```\n",
    "\n",
    "> - map has $O(n)$ work and $O(1)$ span\n",
    "> - scan has $O(n)$ work and $O(\\lg n)$ span\n",
    "> - reduce has $O(n)$ work and $O(\\lg n)$ span\n",
    "> - So, combination has $O(n)$ work and $O(\\lg n)$ span\n",
    "\n",
    "\n",
    "**2e. divide and conquer solution** Implement `parens_match_dc_helper`, a divide and conquer solution to the problem. A key observation is that we *cannot* simply solve each subproblem using the above solutions and combine the results. E.g., consider '((()))', which would be split into '(((' and ')))', neither of which is matched. Yet, the whole input is matched. Instead, we'll have to keep track of two numbers: the number of unmatched right parentheses (R), and the number of unmatched left parentheses (L). `parens_match_dc_helper` returns a tuple (R,L). So, if the input is just '(', then `parens_match_dc_helper` returns (0,1), indicating that there is 1 unmatched left parens and 0 unmatched right parens. Analogously, if the input is just ')', then the result should be (1,0). The main difficulty is deciding how to merge the returned values for the two recursive calls. E.g., if (i,j) is the result for the left half of the list, and (k,l) is the output of the right half of the list, how can we compute the proper return value (R,L) using only i,j,k,l? Try a few example inputs to guide your solution, then test with `test_parens_match_dc_helper`.\n",
    "\n",
    "\n",
    "\n",
    ".  \n",
    ". \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "**2f.** What are the recurrences for the Work and Span of this solution? What are their Big Oh solutions?\n",
    "\n",
    "> $W(n) = 2W(n/2) + 1$\n",
    "\n",
    "> leaf dominated: 1 -> 2 -> 4 -> 8 -> ... \n",
    "\n",
    "> number of leaves is $2^{\\lg n}$\n",
    "\n",
    "> -> $O(n)$\n",
    "\n",
    ".  \n",
    ".  \n",
    "\n",
    "> $S(n) = S(n/2) + 1$\n",
    "\n",
    "> balanced: 1 -> 1 -> 1 -> ...\n",
    "\n",
    "> -> $O(\\lg n)$\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# parens match\n",
    "import math    \n",
    "\n",
    "def iterate(f, x, a):\n",
    "    \"\"\"\n",
    "    Params:\n",
    "      f.....function to apply\n",
    "      x.....return when a is empty\n",
    "      a.....input sequence\n",
    "    \"\"\"\n",
    "    if len(a) == 0:\n",
    "        return x\n",
    "    else:\n",
    "        return iterate(f, f(x, a[0]), a[1:])\n",
    "\n",
    "def parens_update(current_output, next_input):\n",
    "    \"\"\"\n",
    "    This function will be passed to the `iterate` function to \n",
    "    solve the balanced parenthesis problem.\n",
    "    \n",
    "    Like all functions used by iterate, it takes in:\n",
    "    current_output....the cumulative output thus far (e.g., the running sum when doing addition)\n",
    "    next_input........the next value in the input\n",
    "    \n",
    "    Returns:\n",
    "      the updated value of `current_output`\n",
    "    \"\"\"\n",
    "    ###TODO    \n",
    "# #     # almost but not quite: consider \") (\"\n",
    "#     if next_input == '(':            # new open parens \n",
    "#         return current_output + 1\n",
    "#     elif next_input == ')':          # new close parens\n",
    "#         return current_output - 1\n",
    "#     else:\n",
    "#         return current_output\n",
    "        \n",
    "    \n",
    "    if current_output == -math.inf:  # in an invalid state; carry it forward\n",
    "        return current_output\n",
    "    if next_input == '(':            # new open parens \n",
    "        return current_output + 1\n",
    "    elif next_input == ')':          # new close parens\n",
    "        if current_output <= 0:      # close before an open -> invalid\n",
    "            return -math.inf\n",
    "        else:                        # valid\n",
    "            return current_output - 1\n",
    "    else:                            # ignore non-parens input\n",
    "        return current_output\n",
    "    ###\n",
    "    \n",
    "def parens_match_iterative(mylist):\n",
    "    \"\"\"\n",
    "    Implement the iterative solution to the parens matching problem.\n",
    "    This function should call `iterate` using the `parens_update` function.\n",
    "    \n",
    "    Params:\n",
    "      mylist...a list of strings\n",
    "    Returns\n",
    "      True if the parenthesis are matched, False otherwise\n",
    "      \n",
    "    e.g.,\n",
    "    >>>parens_match_iterative(['(', 'a', ')'])\n",
    "    True\n",
    "    >>>parens_match_iterative(['('])\n",
    "    False\n",
    "    \"\"\"\n",
    "    ### TODO\n",
    "    return iterate(parens_update, 0, mylist) == 0\n",
    "    ###\n",
    "\n",
    "def test_parens_match_iterative():\n",
    "    assert parens_match_iterative(['(', ')']) == True\n",
    "    assert parens_match_iterative(['(']) == False\n",
    "    assert parens_match_iterative([')']) == False\n",
    "    assert parens_match_iterative(['(', 'a', ')', '(', ')']) == True\n",
    "    assert parens_match_iterative(['(',  '(', '(', ')', ')', ')']) == True\n",
    "    assert parens_match_iterative(['(', '(', ')']) == False\n",
    "    assert parens_match_iterative(['(', 'a', ')', ')', '(']) == False\n",
    "    assert parens_match_iterative([]) == True\n",
    "    \n",
    "test_parens_match_iterative()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "code_folding": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 0, -1, 0] 0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def scan(f, id_, a):\n",
    "    \"\"\"\n",
    "    This is a horribly inefficient implementation of scan\n",
    "    only to understand what it does.\n",
    "    We'll discuss how to make it more efficient later.\n",
    "    \"\"\"\n",
    "    return (\n",
    "            [reduce(f, id_, a[:i+1]) for i in range(len(a))],\n",
    "             reduce(f, id_, a)\n",
    "           )\n",
    "\n",
    "def paren_map(x):\n",
    "    \"\"\"\n",
    "    Returns 1 if input is '(', -1 if ')', 0 otherwise.\n",
    "    This will be used by your `parens_match_scan` function.\n",
    "    \n",
    "    Params:\n",
    "       x....an element of the input to the parens match problem (e.g., '(' or 'a')\n",
    "       \n",
    "    >>>paren_map('(')\n",
    "    1\n",
    "    >>>paren_map(')')\n",
    "    -1\n",
    "    >>>paren_map('a')\n",
    "    0\n",
    "    \"\"\"\n",
    "    if x == '(':\n",
    "        return 1\n",
    "    elif x == ')':\n",
    "        return -1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "def min_f(x,y):\n",
    "    \"\"\"\n",
    "    Returns the min of x and y. Useful for `parens_match_scan`.\n",
    "    \"\"\"\n",
    "    if x < y:\n",
    "        return x\n",
    "    return y\n",
    "\n",
    "def parens_match_scan(mylist):\n",
    "    \"\"\"\n",
    "    Implement a solution to the parens matching problem using `scan`.\n",
    "    This function should make one call each to `scan`, `map`, and `reduce`\n",
    "    \n",
    "    Params:\n",
    "      mylist...a list of strings\n",
    "    Returns\n",
    "      True if the parenthesis are matched, False otherwise\n",
    "      \n",
    "    e.g.,\n",
    "    >>>parens_match_scan(['(', 'a', ')'])\n",
    "    True\n",
    "    >>>parens_match_scan(['('])\n",
    "    False\n",
    "    \n",
    "    \"\"\"\n",
    "    ###TODO\n",
    "    history, last = scan(plus, 0, list(map(paren_map, mylist)))\n",
    "    print(history, last)\n",
    "    return last == 0 and reduce(min_f, 0, history) >= 0\n",
    "    ###\n",
    "\n",
    "def test_parens_match_scan():\n",
    "    assert parens_match_scan(['(', ')']) == True\n",
    "    assert parens_match_scan(['(']) == False\n",
    "    assert parens_match_scan([')']) == False\n",
    "    assert parens_match_scan(['(', 'a', ')', '(', ')']) == True\n",
    "    assert parens_match_scan(['(',  '(', '(', ')', ')', ')']) == True\n",
    "    assert parens_match_scan(['(', '(', ')']) == False\n",
    "    assert parens_match_scan(['(', 'a', ')', ')', '(']) == False\n",
    "    assert parens_match_scan([]) == True\n",
    "\n",
    "# test_parens_match_scan()    \n",
    "parens_match_scan(['(', ')', ')', '('])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# D&C parens_match\n",
    "\n",
    "def parens_match_dc_helper(mylist):\n",
    "    \"\"\"\n",
    "    Recursive, divide and conquer solution to the parens match problem.\n",
    "    \n",
    "    Returns:\n",
    "      tuple (R, L), where R is the number of unmatched right parentheses, and\n",
    "      L is the number of unmatched left parentheses. This output is used by \n",
    "      parens_match_dc to return the final True or False value\n",
    "    \"\"\"\n",
    "    ###TODO\n",
    "    # Base cases\n",
    "    if len(mylist) == 0:\n",
    "        return [0,0]\n",
    "    elif len(mylist) == 1:\n",
    "        if mylist[0] == '(':\n",
    "            return (0, 1) # one unmatched (\n",
    "        elif mylist[0] == ')':\n",
    "            return (1, 0) # one unmatched )    \n",
    "        else:\n",
    "            return (0, 0)\n",
    "    r1,l1 = parens_match_dc_helper(mylist[:len(mylist)//2])\n",
    "    r2,l2 = parens_match_dc_helper(mylist[len(mylist)//2:])\n",
    "    # Combination:\n",
    "    # Return the tuple (R,L) using some combination of the values i,j,k,l defined above.\n",
    "    # This should be done in constant time.\n",
    "    if l1 > r2:\n",
    "        return (r1, (l1 - r2) + l2)\n",
    "    else:\n",
    "        return ( (r2 - l1) + r1,   l2)\n",
    "    ###\n",
    "    # if we did this, would return negative values \n",
    "    # return ((r2-l1)+r1, (l1-r2)+l2)\n",
    "    \n",
    "def parens_match_dc(mylist):\n",
    "    \"\"\"\n",
    "    Calls parens_match_dc_helper. If the result is (0,0),\n",
    "    that means there are no unmatched parentheses, so the input is valid.\n",
    "    \n",
    "    Returns:\n",
    "      True if parens_match_dc_helper returns (0,0); otherwise False\n",
    "    \"\"\"\n",
    "    # done.\n",
    "    n_unmatched_left, n_unmatched_right = parens_match_dc_helper(mylist)\n",
    "    return n_unmatched_left==0 and n_unmatched_right==0\n",
    "\n",
    "def test_parens_match_dc():\n",
    "    assert parens_match_dc(['(', ')']) == True\n",
    "    assert parens_match_dc(['(']) == False\n",
    "    assert parens_match_dc([')']) == False\n",
    "    assert parens_match_dc(['(', 'a', ')', '(', ')']) == True\n",
    "    assert parens_match_dc(['(',  '(', '(', ')', ')', ')']) == True\n",
    "    assert parens_match_dc(['(', '(', ')']) == False\n",
    "    assert parens_match_dc(['(', 'a', ')', ')', '(']) == False\n",
    "    assert parens_match_dc([]) == True    \n",
    "\n",
    "test_parens_match_dc()\n",
    "# parens_match_dc(['(', 'a', ')', ')', '(', ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|input 1 | input 2|$R_1$|$L_1$|$R_2$|$L_2$| ->|$R_o$|$L_o$|\n",
    "|--------|--------|-----|-----|-----|-----|-  |-----|-----|\n",
    "|   (    | )      | 0   | 1   | 1   | 0   |.  |  0  |  0  |\n",
    "|   ( (  | )      | 0   | 2   | 1   | 0   |.  |  0  |  1  |\n",
    "|  ( ( ( | ) ) (  | 0   | 3   | 2   | 1   |.  |  0  |  2  |\n",
    "|   (    | ) ) (  | 0   | 1   | 2   | 1   |.  |  1  |  1  |\n",
    "|   (    | ) (    | 0   | 1   | 1   | 1   |.  |  0  |  1  |\n",
    "|   )    | (      | 1   | 0   | 0   | 1   |.  |  1  |  1  |\n",
    "| ( )    | ( )    | 0   | 0   | 0   | 0   |.  |  0  |  0  |\n",
    "| ( a    | a )    | 0   | 1   | 1   | 0   |.  |  0  |  0  |\n",
    "| ( )    | ) (    | 0   | 0   | 1   | 1   |.  |  1  |  1  |\n",
    "| ( (    | ) )    | 0   | 2   | 2   | 0   |.  |  0  |  0  |\n",
    "| ( (    | ) (    | 0   | 2   | 1   | 1   |.  |  0  |  2  |\n",
    "| ) (    | ) )    | 1   | 1   | 2   | 0   |.  |  2  |  0  |\n",
    "\n",
    "\n",
    "| a ) | ( )  | 1   | 0   | 0   | 0   |.  |  0  |  0  |\n",
    "\n",
    "- $R_1$: number of unmatched right parentheses in input 1\n",
    "- $L_1$: number of unmatched left parentheses in input 1\n",
    "- $R_2$: number of unmatched right parentheses in input 2\n",
    "- $L_2$: number of unmatched left parentheses in input 2\n",
    "\n",
    "If $L_1 > R_2$ $~~~~\\Rightarrow~~~~$ $L_o = (L_1 - R_2) + L_2$\n",
    "\n",
    "If $L_1 \\le R_2$ $~~~~\\Rightarrow~~~~$ $L_o = L_2$\n",
    "\n",
    "If $L_1 > R_2$ $~~~~\\Rightarrow~~~~$ $R_o = R_1$\n",
    "\n",
    "If $L_1 \\le R_2$ $~~~~\\Rightarrow~~~~$ $R_o = (R_2 - L_1) + R_1$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "return_one:  0 2\n"
     ]
    }
   ],
   "source": [
    "l1 = 2\n",
    "r1 = 0\n",
    "l2 = 1\n",
    "r2 = 1\n",
    "\n",
    "if l1 > r2:\n",
    "    print('return_one:  %d %d' % (r1, l2 + l1 - r2))\n",
    "else:\n",
    "    print('return_two %d %d' % (r1 + r2 - l1, l2))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
